{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NPL_DeepLearning_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQe4Xmn_5a_m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "cd02fd46-0b8b-4c97-f2c5-72f32b3f5c50"
      },
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (50.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksPDx4rL5a9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "27a7ac26-49c6-4427-f260-bdc06772f621"
      },
      "source": [
        "!pip install gensim --upgrade\n",
        "!pip install -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 135kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.3\n",
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/f7/4b41b6832abf4c9bef71a664dc563adb25afc5812831667c6db572b1a261/keras-tuner-1.0.1.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.16.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-cp36-none-any.whl size=73200 sha256=98a3c82fc76f20d11f8cc206fd7e4fcde33f7bf11bc96dac2bd3efa4155d6ff4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/cc/62/52716b70dd90f3db12519233c3a93a5360bc672da1a10ded43\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=eb17fbe2ae74583fa8e8c53d5b3078e5b72a66ec05a798fc63420af3e296da46\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.1 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J5HunUR5a6Y"
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Autorizar el acceso a tu propia cuenta de google drive, \n",
        "# siga el enlace, acepte y copie el codigo de verificación."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX_nFLdu5a21"
      },
      "source": [
        "# Model Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense, SimpleRNN, LSTM, GRU, Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from seaborn import heatmap\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from os import getcwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LkwA0nK5a0c"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# File Extraction\n",
        "myfile = drive.CreateFile({'id': '1eOTGLFbP2nhf9YBNC34vQre5pQ4pl1jY'})\n",
        "myfile.GetContentFile('Base_Tweets.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQE3tIJd5axr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "59f609b9-5b15-4574-d00b-4bd6078448bc"
      },
      "source": [
        "# Reading File\n",
        "df = pd.read_csv('Base_Tweets.csv', encoding = 'utf8')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Qué gusto escuchar a una mujer como Maria Blas...</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Es más fácil levantarse por la mañana para cor...</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La presidenta aavv de amigos del canódromo den...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Asi es, eso es lo q importa RT @el_cuartel: @m...</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>El @PSOE pone pegas ahora a encorsetar el gast...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content polarity\n",
              "0  Qué gusto escuchar a una mujer como Maria Blas...        P\n",
              "1  Es más fácil levantarse por la mañana para cor...        P\n",
              "2  La presidenta aavv de amigos del canódromo den...        N\n",
              "3  Asi es, eso es lo q importa RT @el_cuartel: @m...        P\n",
              "4  El @PSOE pone pegas ahora a encorsetar el gast...        N"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfr7xO6s5au1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c4aadf14-2698-4be3-b4f2-0ab90e44d40d"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "\n",
        "def process_tweet(tweet):\n",
        "    \"\"\"Process tweet function.\n",
        "    Input:\n",
        "        tweet: a string containing a tweet\n",
        "    Output:\n",
        "        tweets_clean: a list of words containing the processed tweet\n",
        "\n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('spanish')\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in string.punctuation):  # remove punctuation\n",
        "            # tweets_clean.append(word)\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean\n",
        "\n",
        "\n",
        "def build_freqs(tweets, ys):\n",
        "    \"\"\"Build frequencies.\n",
        "    Input:\n",
        "        tweets: a list of tweets\n",
        "        ys: an m x 1 array with the sentiment label of each tweet\n",
        "            (either 0 or 1)\n",
        "    Output:\n",
        "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
        "        frequency\n",
        "    \"\"\"\n",
        "    # Convert np array to list since zip needs an iterable.\n",
        "    # The squeeze is necessary or the list ends up with one element.\n",
        "    # Also note that this is just a NOP if ys is already a list.\n",
        "    yslist = np.squeeze(ys).tolist()\n",
        "\n",
        "    # Start with an empty dictionary and populate it by looping over all tweets\n",
        "    # and over all processed words in each tweet.\n",
        "    freqs = {}\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "\n",
        "    return freqs\n",
        "\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsqH-hdS5arU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "126bfce8-efe9-42e0-a00d-764d94249f54"
      },
      "source": [
        "X_raw=np.array(df.content)\n",
        "y=np.array(df.polarity)\n",
        "\n",
        "print(X_raw.shape)\n",
        "print(y.shape)\n",
        "\n",
        "print(X_raw[0])\n",
        "print(process_tweet(X_raw[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42367,)\n",
            "(42367,)\n",
            "Qué gusto escuchar a una mujer como Maria Blasco.....y encima nos deja titulares esperanzadores....\n",
            "['gusto', 'escuchar', 'mujer', 'maria', 'blasco', '...', 'encima', 'deja', 'titular', 'esperanzador', '...']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tc_o-3H5alr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf16d93f-d2d9-4ea6-b730-3aa43e70123c"
      },
      "source": [
        "preprocess_list = np.array([process_tweet(x) for x in X_raw])\n",
        "print(preprocess_list.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42367,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A14eZabJ5F-A"
      },
      "source": [
        "# Word to vector\n",
        "maxlen = 100 #max number of word\n",
        "max_words = 20000 #considers the first 20000 words\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(preprocess_list)\n",
        "sequences = tokenizer.texts_to_sequences(preprocess_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khVy9htS9Qcs"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('tokenizer_bbva3.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4hhWlS-9zjw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "741bc8b9-5dfb-4f0a-fb3e-cb907840ec7b"
      },
      "source": [
        "# Word idctionary\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "data = pad_sequences(sequences, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 41457 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfjgRmUg9zzK"
      },
      "source": [
        "# Label Vector\n",
        "sent_dic = dict(zip(df.polarity.unique(), range(len(df.polarity.unique()))))\n",
        "df[\"Sent_Code\"] = [sent_dic[x] for x in df.polarity]\n",
        "Y = keras.utils.to_categorical(df.Sent_Code)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVggM-VE9z2E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "17117c60-0e4b-49f1-ade9-4775a1963271"
      },
      "source": [
        "# Shape of data\n",
        "labels = np.asarray(Y)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (42367, 100)\n",
            "Shape of label tensor: (42367, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr04GrzU9zma"
      },
      "source": [
        "# Data Shuffle\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.seed(170298)\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# Dataset Split\n",
        "x_train, x_val, y_train, y_val = train_test_split(data, labels, test_size = .3)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = .5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmnF9bBQ9zg_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f655c0d8-1ff5-4a4b-d090-3bc7c85adc7b"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(29656, 100)\n",
            "(6355, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnYfSNav98Rw"
      },
      "source": [
        "# Import Embedding\n",
        "myfile = drive.CreateFile({'id': '1TJ5XroELn2aMQKgvSCajA5juqKqQ7Zam'})\n",
        "myfile.GetContentFile('sbw_vectors.bin')\n",
        "\n",
        "embedd = KeyedVectors.load_word2vec_format(\"sbw_vectors.bin\", binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMO2Ahe898Us",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "5d8f8acd-a82d-40a8-ccbb-b931f78e82ae"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(embedd.get_keras_embedding(train_embeddings = False, word_index = word_index))\n",
        "model.add(GRU(16, dropout = 0.1, recurrent_dropout = 0.2, return_sequences = True))\n",
        "model.add(LSTM(64, return_sequences = True))\n",
        "model.add(GRU(64))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(.1))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 300)         12437400  \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, None, 16)          15264     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 64)          20736     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 64)                24960     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 12,500,506\n",
            "Trainable params: 63,106\n",
            "Non-trainable params: 12,437,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UldIJ3Yp98I-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "9b35588b-089b-45a7-c9a8-24c554db0053"
      },
      "source": [
        "# Compilation\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import optimizers\n",
        "\n",
        "batch=337\n",
        "\n",
        "#model.compile(optimizer=optimizers.Adam(lr=.0001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=.001), metrics=['acc']) \n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath= \"Modelo_Ian_7.h5\", monitor='val_acc', verbose=0, \n",
        "                               save_best_only=True, mode='max', period=1)\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=25, batch_size=batch, steps_per_epoch=x_train.shape[0]//batch, validation_data=(x_val, y_val), \n",
        "                    callbacks=[checkpointer])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "88/88 [==============================] - 14s 156ms/step - loss: 0.2290 - acc: 0.9070 - val_loss: 0.3232 - val_acc: 0.8681\n",
            "Epoch 2/25\n",
            "88/88 [==============================] - 13s 144ms/step - loss: 0.2254 - acc: 0.9067 - val_loss: 0.3200 - val_acc: 0.8655\n",
            "Epoch 3/25\n",
            "88/88 [==============================] - 13s 144ms/step - loss: 0.2224 - acc: 0.9099 - val_loss: 0.3325 - val_acc: 0.8606\n",
            "Epoch 4/25\n",
            "88/88 [==============================] - 13s 149ms/step - loss: 0.2188 - acc: 0.9122 - val_loss: 0.3281 - val_acc: 0.8677\n",
            "Epoch 5/25\n",
            "88/88 [==============================] - 13s 143ms/step - loss: 0.2127 - acc: 0.9150 - val_loss: 0.3325 - val_acc: 0.8675\n",
            "Epoch 6/25\n",
            "88/88 [==============================] - 13s 143ms/step - loss: 0.2149 - acc: 0.9118 - val_loss: 0.3310 - val_acc: 0.8651\n",
            "Epoch 7/25\n",
            "88/88 [==============================] - 13s 144ms/step - loss: 0.2141 - acc: 0.9132 - val_loss: 0.3253 - val_acc: 0.8669\n",
            "Epoch 8/25\n",
            "88/88 [==============================] - 13s 143ms/step - loss: 0.2079 - acc: 0.9156 - val_loss: 0.3272 - val_acc: 0.8680\n",
            "Epoch 9/25\n",
            "88/88 [==============================] - 13s 145ms/step - loss: 0.2110 - acc: 0.9155 - val_loss: 0.3326 - val_acc: 0.8661\n",
            "Epoch 10/25\n",
            "88/88 [==============================] - 13s 144ms/step - loss: 0.2029 - acc: 0.9171 - val_loss: 0.3393 - val_acc: 0.8662\n",
            "Epoch 11/25\n",
            "88/88 [==============================] - 13s 145ms/step - loss: 0.2004 - acc: 0.9207 - val_loss: 0.3432 - val_acc: 0.8636\n",
            "Epoch 12/25\n",
            "88/88 [==============================] - 13s 144ms/step - loss: 0.2005 - acc: 0.9183 - val_loss: 0.3390 - val_acc: 0.8658\n",
            "Epoch 13/25\n",
            "88/88 [==============================] - 13s 144ms/step - loss: 0.1975 - acc: 0.9198 - val_loss: 0.3448 - val_acc: 0.8661\n",
            "Epoch 14/25\n",
            "88/88 [==============================] - 13s 144ms/step - loss: 0.1966 - acc: 0.9199 - val_loss: 0.3474 - val_acc: 0.8673\n",
            "Epoch 15/25\n",
            "88/88 [==============================] - 13s 143ms/step - loss: 0.1939 - acc: 0.9206 - val_loss: 0.3369 - val_acc: 0.8666\n",
            "Epoch 16/25\n",
            "88/88 [==============================] - 13s 144ms/step - loss: 0.1912 - acc: 0.9228 - val_loss: 0.3479 - val_acc: 0.8655\n",
            "Epoch 17/25\n",
            "88/88 [==============================] - 13s 146ms/step - loss: 0.1895 - acc: 0.9237 - val_loss: 0.3493 - val_acc: 0.8673\n",
            "Epoch 18/25\n",
            "88/88 [==============================] - 13s 143ms/step - loss: 0.1934 - acc: 0.9223 - val_loss: 0.3538 - val_acc: 0.8667\n",
            "Epoch 19/25\n",
            "88/88 [==============================] - 13s 143ms/step - loss: 0.1861 - acc: 0.9257 - val_loss: 0.3582 - val_acc: 0.8645\n",
            "Epoch 20/25\n",
            "88/88 [==============================] - 13s 143ms/step - loss: 0.1851 - acc: 0.9261 - val_loss: 0.3450 - val_acc: 0.8656\n",
            "Epoch 21/25\n",
            "88/88 [==============================] - 13s 144ms/step - loss: 0.1796 - acc: 0.9290 - val_loss: 0.3569 - val_acc: 0.8647\n",
            "Epoch 22/25\n",
            "88/88 [==============================] - 13s 143ms/step - loss: 0.1789 - acc: 0.9288 - val_loss: 0.3738 - val_acc: 0.8603\n",
            "Epoch 23/25\n",
            "88/88 [==============================] - 13s 144ms/step - loss: 0.1769 - acc: 0.9279 - val_loss: 0.3663 - val_acc: 0.8631\n",
            "Epoch 24/25\n",
            "88/88 [==============================] - 13s 144ms/step - loss: 0.1760 - acc: 0.9303 - val_loss: 0.3754 - val_acc: 0.8562\n",
            "Epoch 25/25\n",
            "88/88 [==============================] - 13s 143ms/step - loss: 0.1744 - acc: 0.9295 - val_loss: 0.3736 - val_acc: 0.8642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOMp24XOVYqA"
      },
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('saved_model/model_Ian_6.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFfJWROFVZWE"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBP5OehA-NfN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f8cf7a45-df27-48d5-b281-564e6786cf1c"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "199/199 [==============================] - 5s 27ms/step - loss: 0.3572 - acc: 0.8730\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35721632838249207, 0.873033344745636]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4gemLCB-NVg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "5a8e3ee2-7ffc-4655-cad0-7d812f0a0362"
      },
      "source": [
        "\n",
        "# Prediction and confussion matrix\n",
        "#predic = model.predict_classes(x_test)\n",
        "predic = (model.predict_proba(x_test)[:,1] >= 0.448)\n",
        "true = [np.argmax(x) for x in y_test]\n",
        "\n",
        "cm = confusion_matrix(true, predic)\n",
        "heatmap(cm, annot = True, fmt = 'd')\n",
        "resultado = (cm[0][0] + cm[1][1]) / y_test.shape[0]\n",
        "print(resultado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8758653241032096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WXFNgfUgG2E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f4a95ba5-0659-4b3b-9300-613fee1f736e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import kerastuner as kt\n",
        "print(tf.__version__)\n",
        "print(kt.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30a7pS8jjMKb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtQZJSUIEj95"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkX6fQHEf0qg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzegp43NgtsX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpcWC8y4gtvv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVikc1bCgtpK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}